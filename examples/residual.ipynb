{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first tutorial on DSA! We'll recreate the third figure from the paper (except the Procrustes analysis). In doing so, we'll learn about how to structure our data matrices to fit into DSA, how to apply the DSA to data, and how to select various paramters for DSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'DSA'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mDSA\u001b[39;00m \u001b[39mimport\u001b[39;00m DSA\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'DSA'"
     ]
    }
   ],
   "source": [
    "from DSA import DSA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import MDS\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "rng = np.random.default_rng(2023)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to define our models, which we construct as ordinary differential equations. There are 3 types of models:\n",
    "* Bistable switch (nonlinear system)\n",
    "* Line attractor (linear system)\n",
    "* Point attractor (linear system)\n",
    "\n",
    "The goal of this demonstration is to show that even the condition averaged trajectories sampled from these systems are the same, DSA can distinguish between the systems. \n",
    "\n",
    "How do we do this? Thanks to Galgali et al., (Nat. Neuro, 2023), we can construct three systems with different intrinsic dynamics that can be controlled to have the same condition averages. The process is a very simple feedback linearization scheme. We'll sample from the first system first and then use those condition averages to drive the latter two systems. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining our models\n",
    "def run_model1(cohs,params,time=100,cond_avgs=None,seeded=False):\n",
    "    '''\n",
    "    simple saddle model\n",
    "    '''\n",
    "    a = params.get('a',-.6)\n",
    "    b = params.get('b',2)\n",
    "    c = params.get('c',-1)\n",
    "    dt = params.get('dt',1)\n",
    "    ntrials = params.get('ntrials',10)\n",
    "    sigma = params.get('sigma',0)\n",
    "    steps = int(time / dt)\n",
    "    x = np.zeros((len(cohs),ntrials,steps,2))\n",
    "    cohs = np.array(cohs)\n",
    "    cohs = np.repeat(cohs[:,np.newaxis],ntrials,axis=1)\n",
    "    input_optimized = np.zeros((len(cohs),ntrials,steps,2))\n",
    "    for i in range(1,steps):\n",
    "        dx = a*x[:,:,i-1,0]**3 + b*x[:,:,i-1,0] + cohs\n",
    "        dy = c*x[:,:,i-1,1] + cohs\n",
    "        dx = np.concatenate([dx[:,:,np.newaxis],dy[:,:,np.newaxis]],axis=2)\n",
    "        if cond_avgs is not None:\n",
    "            xavg = x[:,:,i-1].mean(axis=1)\n",
    "            \n",
    "            dx_avg = a*xavg[:,-1]**3 + b*xavg[:,-1] + cohs.mean(axis=1)\n",
    "            dy_avg = c*xavg[:,-1] + cohs.mean(axis=1)\n",
    "            dx_avg = np.concatenate([dx_avg[:,np.newaxis],dy_avg[:,np.newaxis]],axis=1)\n",
    "            inp = (1/dt) * (cond_avgs[:,i] - xavg - dx_avg * dt)\n",
    "            input_optimized[:,:,i] = np.repeat(inp[:,np.newaxis],ntrials,axis=1)\n",
    "        else:\n",
    "            input_optimized[:,:,i] = 0\n",
    "        \n",
    "        if seeded:\n",
    "            rand = rng.normal(0,sigma,size=(len(cohs),ntrials,2))\n",
    "        else:\n",
    "            rand =  np.random.normal(0,sigma,size=(len(cohs),ntrials,2))\n",
    "        x[:,:,i] = x[:,:,i-1] + dt * (dx + input_optimized[:,:,i] + rand)\n",
    "               \n",
    "    #xdot = [ax^3 + bx, cy]\n",
    "    cond_avg = np.mean(x,axis=1)\n",
    "    return x,cond_avg\n",
    "\n",
    "def run_model2(cond_avgs,params,time=100):\n",
    "    '''\n",
    "    line attractor model\n",
    "    '''\n",
    "    l0 = params.get('l0',[1,1])\n",
    "    l0 /= np.linalg.norm(l0)\n",
    "    r0 = params.get('r0',[1,0])\n",
    "    sigma = params.get('sigma',0)\n",
    "    dt = params.get('dt',1)\n",
    "    ntrials = params.get('ntrials',10)\n",
    "    eval1 = params.get('eval1',-1)\n",
    "    evals = np.diag([0,eval1])\n",
    "    # Mrot = np.array([[0,-1],[1,0]])\n",
    "    # r1 = Mrot @ l0\n",
    "    r1 = l0\n",
    "    R = np.array([r0,r1])\n",
    "    L = np.linalg.inv(R)\n",
    "    A = R @ evals @ L\n",
    "    theta = np.radians(45)\n",
    "    c, s = np.cos(theta), np.sin(theta)\n",
    "    Mrot = np.array(((c, -s), (s, c)))\n",
    "    A = Mrot @ A\n",
    "\n",
    "    steps = int(time / dt)\n",
    "    x = np.zeros((cond_avgs.shape[0],ntrials,steps,2))\n",
    "    input_optimized = np.zeros((cond_avgs.shape[0],ntrials,steps,2))\n",
    "    for i in range(1,steps):\n",
    "        dx = np.einsum('ij,mkj->mki',A,x[:,:,i-1])\n",
    "        #dx = A @ x[:,:,i-1]    \n",
    "        # dx_avg = np.einsum('ij,mkj->mki',A,cond_avgs[:,i-1])\n",
    "        xavg = x[:,:,i-1].mean(axis=1)\n",
    "        dx_avg = A @ xavg #cond_avgs[:,i-1]\n",
    "        inp = (1/dt) * (cond_avgs[:,i] - xavg - dx_avg * dt)\n",
    "        input_optimized[:,:,i] = np.repeat(inp[:,np.newaxis],ntrials,axis=1)\n",
    "        # diff = cond_avgs[:,i] - x[:,:,i-1].mean(axis=1)\n",
    "        # opt_input = (diff - dx.mean(axis=1)) \n",
    "        # input_optimized[:,:,i-1] = np.repeat(opt_input[:,np.newaxis],ntrials,axis=1)\n",
    "        x[:,:,i] = x[:,:,i-1] + dt*(dx + input_optimized[:,:,i] + \n",
    "                np.random.normal(0,sigma,size=(cond_avgs.shape[0],ntrials,2)))\n",
    "    return x, input_optimized\n",
    "\n",
    "def run_model3(cond_avgs,params,time=100):\n",
    "    a1 = params.get('a1',-0.5)\n",
    "    a2 = params.get('a2',-1)\n",
    "    A = np.diag([-np.abs(a1),-np.abs(a2)])\n",
    "    sigma = params.get('sigma',0)\n",
    "    dt = params.get('dt',1)\n",
    "    steps = int(time / dt)\n",
    "    ntrials = params.get('ntrials',10)\n",
    "    x = np.zeros((cond_avgs.shape[0],ntrials,steps,2))\n",
    "    input_optimized = np.zeros((cond_avgs.shape[0],ntrials,steps,2))\n",
    "    for i in range(1,steps):\n",
    "        dx = np.einsum('ij,mkj->mki',A,x[:,:,i-1])\n",
    "        #dx = A @ x[:,:,i-1]\n",
    "        xavg = x[:,:,i-1].mean(axis=1)\n",
    "        dx_avg = A @ xavg #cond_avgs[:,i-1]\n",
    "        # dx_avg = np.einsum('ij,mj->mi',A,cond_avgs[:,i-1])\n",
    "        inp = (1/dt) * (cond_avgs[:,i] - xavg - dx_avg * dt)\n",
    "        input_optimized[:,:,i] = np.repeat(inp[:,np.newaxis],ntrials,axis=1)      \n",
    "          # diff = cond_avgs[:,i] - x[:,:,i-1].mean(axis=1)\n",
    "        # opt_input = (diff - dx.mean(axis=1)) \n",
    "        # input_optimized[:,:,i-1] = np.repeat(opt_input[:,np.newaxis],ntrials,axis=1)\n",
    "        x[:,:,i] = x[:,:,i-1] + dt*(dx + input_optimized[:,:,i] + \n",
    "               np.random.normal(0,sigma,size=(cond_avgs.shape[0],ntrials,2)))\n",
    "    return x, input_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's visualize a sample from each \n",
    "x1,cond_avg = run_model1([-.1,.1],dict(dt=0.01,sigma=0.1,ntrials=20))\n",
    "print(x1.shape,cond_avg.shape)\n",
    "\n",
    "x2,input_optimized2 = run_model2(cond_avg,dict(dt=0.01,sigma=0.1,ntrials=20))\n",
    "cond_avg2 = x2.mean(axis=1)\n",
    "print(x2.shape,cond_avg2.shape)\n",
    "\n",
    "x3,input_optimized3 = run_model3(cond_avg,dict(dt=0.01,sigma=0.1,ntrials=20))\n",
    "cond_avg3 = x3.mean(axis=1)\n",
    "print(x3.shape,cond_avg3.shape)\n",
    "\n",
    "fig,ax = plt.subplots(1,3,figsize=(8,3),sharex=True,sharey=True)\n",
    "for i in range(x1.shape[0]):\n",
    "    for k in range(3):\n",
    "        ax[k].plot(cond_avg[i,:,0],cond_avg[i,:,1])\n",
    "    for j in range(x1.shape[1]):\n",
    "        if j == 10:\n",
    "            break\n",
    "        for k in range(3):\n",
    "            ax[k].plot(x1[i,j,:,0],x1[i,j,:,1],c=\"orange\" if i else \"blue\", alpha = 0.2)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_ylim(-0.15,0.15)\n",
    "    ax[i].set_xlabel(r\"$h_1$\")\n",
    "ax[0].set_ylabel(r\"$h_2$\")\n",
    "\n",
    "ax[0].set_title(\"Saddle Point\")\n",
    "ax[1].set_title(\"Line Attractor\")\n",
    "ax[2].set_title(\"Point Attractor\")\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some code that's relevant for processing our data\n",
    "def flatten_x(x1):\n",
    "    return x1.reshape(x1.shape[0]*x1.shape[1],x1.shape[2],x1.shape[3])\n",
    "\n",
    "def reshape_cavg(cond_avg):\n",
    "    return cond_avg.reshape(cond_avg.shape[0]*cond_avg.shape[1],cond_avg.shape[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the parameters for our samples and our dmd\n",
    "nmodels = 30 #3 x nmodels total\n",
    "sigma = 0.05 #trajectory noise\n",
    "\n",
    "ntrials = 300 #number of trajectories per model\n",
    "dt = 0.01 #timestep simulated in the odes\n",
    "\n",
    "\n",
    "#vary params for model 1\n",
    "a = np.random.uniform(-5,-3,size=nmodels)  \n",
    "b = np.random.uniform(4,7,size=nmodels)\n",
    "c = np.random.uniform(-4,-2,size=nmodels)\n",
    "\n",
    "#vary params for model 2\n",
    "eval1 = np.random.uniform(-1,-3,size=nmodels)\n",
    "\n",
    "#vary params for model 3\n",
    "a1 = np.random.uniform(-2,-5,size=nmodels)\n",
    "a2 = np.random.uniform(-8,-10,size=nmodels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "model_names = []\n",
    "# modelnames = {1:'bistable', 2:'line attractor', 3:'point attractor'}\n",
    "for i in range(nmodels):    \n",
    "    x1,cond_avg = run_model1([-.1,.1],dict(dt=dt,sigma=sigma,ntrials=ntrials,a=a[i],b=b[i],c=c[i]))  \n",
    "\n",
    "    cavg_baseline = cond_avg #if we want to reset this every time\n",
    "    #x has shape conditions x trials x time x dimension\n",
    "    models.append(x2)\n",
    "    model_names.append('bistable')\n",
    "\n",
    "    x2,input_optimized = run_model2(cavg_baseline,dict(dt=dt,sigma=sigma,ntrials=ntrials,eval1=eval1[i]))\n",
    "    models.append(x2)\n",
    "    model_names.append('line attractor')\n",
    "\n",
    "    x3,input_optimized = run_model3(cavg_baseline,dict(dt=dt,sigma=sigma,ntrials=ntrials,a1=a1[i],a2=a2[i]))\n",
    "    models.append(x3)\n",
    "    model_names.append('point attractor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dmd parameters, all others are default for now.\n",
    "n_delays = 50\n",
    "delay_interval = 20\n",
    "rank = 30\n",
    "\n",
    "dsa = DSA(models,n_delays=n_delays,rank=rank,delay_interval=delay_interval)\n",
    "similarites = dmd.fit_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Model Type'] = model_names\n",
    "reduced = MDS(dissimilarity='precomputed').fit_transform(similarities)\n",
    "df[\"0\"] = lowd_embedding[:,0] \n",
    "df[\"1\"] = lowd_embedding[:,1]\n",
    "\n",
    "palette = 'plasma'\n",
    "sns.scatterplot(data=df,x=\"0\",y=\"1\",hue=\"Model Type\",palette=palette)\n",
    "plt.xlabel(f\"MDS 1\")\n",
    "plt.ylabel(f\"MDS 2\")\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsapublic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
